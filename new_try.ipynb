{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc4aa5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Akshaya\\Annnnacoonda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 8s 1s/step - loss: 4728.3110 - accuracy: 0.0744 - val_loss: 9030.8027 - val_accuracy: 0.1290\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 3s 880ms/step - loss: 4575.2803 - accuracy: 0.0826 - val_loss: 5930.0659 - val_accuracy: 0.0645\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 3s 908ms/step - loss: 2377.7781 - accuracy: 0.1736 - val_loss: 2766.6663 - val_accuracy: 0.0968\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 4s 891ms/step - loss: 1308.0781 - accuracy: 0.1074 - val_loss: 1094.6866 - val_accuracy: 0.1290\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 4s 903ms/step - loss: 498.7694 - accuracy: 0.2066 - val_loss: 667.5798 - val_accuracy: 0.0645\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 4s 906ms/step - loss: 337.6754 - accuracy: 0.1983 - val_loss: 268.2983 - val_accuracy: 0.0323\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 4s 927ms/step - loss: 163.1077 - accuracy: 0.2975 - val_loss: 194.7062 - val_accuracy: 0.0968\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 4s 919ms/step - loss: 101.5288 - accuracy: 0.3967 - val_loss: 129.0125 - val_accuracy: 0.0323\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 4s 892ms/step - loss: 45.4944 - accuracy: 0.5124 - val_loss: 88.3090 - val_accuracy: 0.0323\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 4s 897ms/step - loss: 12.4334 - accuracy: 0.6942 - val_loss: 85.1833 - val_accuracy: 0.0645\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 4s 899ms/step - loss: 4.6649 - accuracy: 0.7934 - val_loss: 70.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 4s 886ms/step - loss: 2.0738 - accuracy: 0.8512 - val_loss: 54.0814 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 4s 895ms/step - loss: 0.5519 - accuracy: 0.9008 - val_loss: 49.1651 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 3s 892ms/step - loss: 0.2198 - accuracy: 0.9256 - val_loss: 49.4868 - val_accuracy: 0.0323\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 3s 884ms/step - loss: 0.3577 - accuracy: 0.9174 - val_loss: 47.3988 - val_accuracy: 0.0323\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 4s 905ms/step - loss: 0.1102 - accuracy: 0.9752 - val_loss: 44.8974 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 4s 896ms/step - loss: 0.0995 - accuracy: 0.9835 - val_loss: 44.0942 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 4s 903ms/step - loss: 0.0896 - accuracy: 0.9835 - val_loss: 44.1989 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 3s 879ms/step - loss: 0.0800 - accuracy: 0.9835 - val_loss: 44.4613 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 3s 862ms/step - loss: 0.0712 - accuracy: 0.9835 - val_loss: 44.7168 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 3s 879ms/step - loss: 0.0538 - accuracy: 0.9917 - val_loss: 45.0842 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 4s 902ms/step - loss: 0.0415 - accuracy: 0.9917 - val_loss: 45.4836 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 3s 868ms/step - loss: 0.0262 - accuracy: 0.9917 - val_loss: 45.6732 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 3s 879ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 45.8450 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 4s 911ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 46.0465 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 4s 887ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 46.2438 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 3s 883ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 46.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 3s 882ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 46.6033 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 3s 878ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 46.7356 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 3s 884ms/step - loss: 8.2054e-04 - accuracy: 1.0000 - val_loss: 46.8372 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 3s 878ms/step - loss: 6.5084e-04 - accuracy: 1.0000 - val_loss: 46.9122 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 4s 931ms/step - loss: 5.4678e-04 - accuracy: 1.0000 - val_loss: 46.9681 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 4s 970ms/step - loss: 4.8429e-04 - accuracy: 1.0000 - val_loss: 47.0152 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 3s 889ms/step - loss: 4.1159e-04 - accuracy: 1.0000 - val_loss: 47.0620 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 4s 911ms/step - loss: 3.5587e-04 - accuracy: 1.0000 - val_loss: 47.1056 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 3s 882ms/step - loss: 3.1306e-04 - accuracy: 1.0000 - val_loss: 47.1429 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 3s 886ms/step - loss: 2.7783e-04 - accuracy: 1.0000 - val_loss: 47.1795 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 4s 939ms/step - loss: 2.2421e-04 - accuracy: 1.0000 - val_loss: 47.2104 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 4s 893ms/step - loss: 2.0470e-04 - accuracy: 1.0000 - val_loss: 47.2378 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 3s 889ms/step - loss: 1.7982e-04 - accuracy: 1.0000 - val_loss: 47.2662 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 4s 967ms/step - loss: 1.6152e-04 - accuracy: 1.0000 - val_loss: 47.2954 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 3s 861ms/step - loss: 1.4529e-04 - accuracy: 1.0000 - val_loss: 47.3185 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 4s 874ms/step - loss: 1.3466e-04 - accuracy: 1.0000 - val_loss: 47.3347 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 4s 905ms/step - loss: 1.2691e-04 - accuracy: 1.0000 - val_loss: 47.3574 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 3s 885ms/step - loss: 1.1811e-04 - accuracy: 1.0000 - val_loss: 47.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 3s 883ms/step - loss: 9.0764e-05 - accuracy: 1.0000 - val_loss: 47.4493 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 3s 883ms/step - loss: 7.4278e-05 - accuracy: 1.0000 - val_loss: 47.4904 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 4s 891ms/step - loss: 6.6491e-05 - accuracy: 1.0000 - val_loss: 47.5217 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 4s 888ms/step - loss: 6.0662e-05 - accuracy: 1.0000 - val_loss: 47.5458 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 3s 874ms/step - loss: 5.5246e-05 - accuracy: 1.0000 - val_loss: 47.5594 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 3s 880ms/step - loss: 5.2235e-05 - accuracy: 1.0000 - val_loss: 47.5710 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 4s 940ms/step - loss: 4.8427e-05 - accuracy: 1.0000 - val_loss: 47.5795 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 4.5748e-05 - accuracy: 1.0000 - val_loss: 47.5866 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 4.2674e-05 - accuracy: 1.0000 - val_loss: 47.5950 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 4s 926ms/step - loss: 4.0440e-05 - accuracy: 1.0000 - val_loss: 47.5973 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 902ms/step - loss: 3.8527e-05 - accuracy: 1.0000 - val_loss: 47.6017 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.5942e-05 - accuracy: 1.0000 - val_loss: 47.5927 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 4s 975ms/step - loss: 3.4353e-05 - accuracy: 1.0000 - val_loss: 47.5839 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 4s 911ms/step - loss: 3.2848e-05 - accuracy: 1.0000 - val_loss: 47.5743 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 4s 912ms/step - loss: 3.1299e-05 - accuracy: 1.0000 - val_loss: 47.5716 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 3s 872ms/step - loss: 3.0088e-05 - accuracy: 1.0000 - val_loss: 47.5766 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 3s 835ms/step - loss: 2.8807e-05 - accuracy: 1.0000 - val_loss: 47.5772 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 3s 878ms/step - loss: 2.7660e-05 - accuracy: 1.0000 - val_loss: 47.5798 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 4s 996ms/step - loss: 2.6488e-05 - accuracy: 1.0000 - val_loss: 47.5846 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 4s 963ms/step - loss: 2.5637e-05 - accuracy: 1.0000 - val_loss: 47.5888 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 4s 902ms/step - loss: 2.4799e-05 - accuracy: 1.0000 - val_loss: 47.5902 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 4s 952ms/step - loss: 2.3904e-05 - accuracy: 1.0000 - val_loss: 47.5900 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 4s 990ms/step - loss: 2.3075e-05 - accuracy: 1.0000 - val_loss: 47.5933 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 2.2312e-05 - accuracy: 1.0000 - val_loss: 47.5944 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 4s 999ms/step - loss: 2.1643e-05 - accuracy: 1.0000 - val_loss: 47.5957 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 5s 1s/step - loss: 2.1002e-05 - accuracy: 1.0000 - val_loss: 47.5957 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 2.0299e-05 - accuracy: 1.0000 - val_loss: 47.5970 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 2s 621ms/step - loss: 1.9630e-05 - accuracy: 1.0000 - val_loss: 47.5953 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 1.9025e-05 - accuracy: 1.0000 - val_loss: 47.5958 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 3s 876ms/step - loss: 1.8478e-05 - accuracy: 1.0000 - val_loss: 47.5968 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 1.7990e-05 - accuracy: 1.0000 - val_loss: 47.5981 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 3s 757ms/step - loss: 1.7349e-05 - accuracy: 1.0000 - val_loss: 47.5986 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 1.6829e-05 - accuracy: 1.0000 - val_loss: 47.5965 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 3s 850ms/step - loss: 1.5873e-05 - accuracy: 1.0000 - val_loss: 47.5993 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 3s 739ms/step - loss: 1.4876e-05 - accuracy: 1.0000 - val_loss: 47.6032 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 3s 845ms/step - loss: 1.4427e-05 - accuracy: 1.0000 - val_loss: 47.6115 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 3s 836ms/step - loss: 1.3834e-05 - accuracy: 1.0000 - val_loss: 47.6183 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 3s 827ms/step - loss: 1.3394e-05 - accuracy: 1.0000 - val_loss: 47.6236 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 3s 835ms/step - loss: 1.2937e-05 - accuracy: 1.0000 - val_loss: 47.6289 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 3s 880ms/step - loss: 1.2611e-05 - accuracy: 1.0000 - val_loss: 47.6348 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 3s 782ms/step - loss: 1.2210e-05 - accuracy: 1.0000 - val_loss: 47.6402 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 1.1844e-05 - accuracy: 1.0000 - val_loss: 47.6464 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 2s 595ms/step - loss: 1.1570e-05 - accuracy: 1.0000 - val_loss: 47.6521 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 1.1185e-05 - accuracy: 1.0000 - val_loss: 47.6574 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 3s 815ms/step - loss: 1.0943e-05 - accuracy: 1.0000 - val_loss: 47.6615 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 3s 820ms/step - loss: 1.0683e-05 - accuracy: 1.0000 - val_loss: 47.6657 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 3s 765ms/step - loss: 1.0417e-05 - accuracy: 1.0000 - val_loss: 47.6690 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 3s 757ms/step - loss: 1.0116e-05 - accuracy: 1.0000 - val_loss: 47.6727 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 3s 867ms/step - loss: 9.8654e-06 - accuracy: 1.0000 - val_loss: 47.6760 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 3s 812ms/step - loss: 9.6733e-06 - accuracy: 1.0000 - val_loss: 47.6794 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 3s 839ms/step - loss: 9.4054e-06 - accuracy: 1.0000 - val_loss: 47.6828 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 9.2114e-06 - accuracy: 1.0000 - val_loss: 47.6858 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 8.9287e-06 - accuracy: 1.0000 - val_loss: 47.6893 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 8.7544e-06 - accuracy: 1.0000 - val_loss: 47.6925 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 8.5899e-06 - accuracy: 1.0000 - val_loss: 47.6968 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Akshaya\\Annnnacoonda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img,img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Step 1: Load your data\n",
    "df = pd.read_csv(\"train.csv\")  # replace with your csv file\n",
    "\n",
    "# Step 2: Split your data into a training set and a test set\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)  # adjust test_size as needed\n",
    "\n",
    "# Step 3: Load your images and labels\n",
    "def load_images_and_labels(df):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        img = load_img(row['image'])  # replace 'image_path' with your image path column\n",
    "        img = img_to_array(img)\n",
    "        images.append(img)\n",
    "        labels.append(row['label'])  # replace 'emotion' with your emotion label column\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "train_images, train_labels = load_images_and_labels(train_df)\n",
    "test_images, test_labels = load_images_and_labels(test_df)\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_labels = le.fit_transform(train_labels)\n",
    "test_labels = le.transform(test_labels)\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Step 4: Build your model\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)),  # input_shape matches RGB images\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(8, activation='softmax')  # replace num_classes with actual number of classes\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train your model\n",
    "model.fit(train_images, train_labels, epochs=100, validation_data=(test_images, test_labels))  # adjust epochs as needed\n",
    "\n",
    "# Step 6: Save your model\n",
    "model.save('your_model.h5')  # replace with your preferred filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8d338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"your_model.json\",'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86a740f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('your_model.h5')\n",
    "df=pd.read_csv('test.csv')\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(150, 150))\n",
    "\n",
    "# Load the image you want to make a prediction for\n",
    "  # replace with the path to your image and make sure the target size matches your model's expected input size\n",
    "\n",
    "# Preprocess the image to a 4D tensor\n",
    "    img_array = img_to_array(img)\n",
    "    img_batch = np.expand_dims(img_array, axis=0)\n",
    "    return img_batch\n",
    "\n",
    "predictions=[]\n",
    "for image_path in df[\"image\"]:\n",
    "    img=preprocess_image(image_path)\n",
    "\n",
    "# Predict the emotion of the image\n",
    "    emotion_prediction = model.predict(img)\n",
    "\n",
    "# The prediction will be a 2D numpy array where each sub-array contains confidence scores for each emotion.\n",
    "# We can use np.argmax to find the index of the highest confidence score.\n",
    "    emotion_index = np.argmax(emotion_prediction)\n",
    "\n",
    "# Then, we can use the LabelEncoder from training to convert this numeric label back into the original (text-based) label\n",
    "    emotion = le.inverse_transform([emotion_index])[0]\n",
    "    predictions.append(emotion)\n",
    "\n",
    "df[\"predictions\"]=predictions\n",
    "\n",
    "df.to_csv(\"test_with_predictions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d88ae8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>C:/Users/Sbala/Emotion/Images/Test\\Anger\\0.jpg</td>\n",
       "      <td>Anger</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C:/Users/Sbala/Emotion/Images/Test\\Anger\\1.jpg</td>\n",
       "      <td>Anger</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C:/Users/Sbala/Emotion/Images/Test\\Anger\\10.jpg</td>\n",
       "      <td>Anger</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C:/Users/Sbala/Emotion/Images/Test\\Anger\\11.jpg</td>\n",
       "      <td>Anger</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C:/Users/Sbala/Emotion/Images/Test\\Anger\\12.jpg</td>\n",
       "      <td>Anger</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>147</td>\n",
       "      <td>C:/Users/Sbala/Emotion/Images/Test\\Surprised\\5...</td>\n",
       "      <td>Surprised</td>\n",
       "      <td>Surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>148</td>\n",
       "      <td>C:/Users/Sbala/Emotion/Images/Test\\Surprised\\6...</td>\n",
       "      <td>Surprised</td>\n",
       "      <td>Surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>149</td>\n",
       "      <td>C:/Users/Sbala/Emotion/Images/Test\\Surprised\\7...</td>\n",
       "      <td>Surprised</td>\n",
       "      <td>Surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>C:/Users/Sbala/Emotion/Images/Test\\Surprised\\8...</td>\n",
       "      <td>Surprised</td>\n",
       "      <td>Surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>151</td>\n",
       "      <td>C:/Users/Sbala/Emotion/Images/Test\\Surprised\\9...</td>\n",
       "      <td>Surprised</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                              image      label  \\\n",
       "0             0     C:/Users/Sbala/Emotion/Images/Test\\Anger\\0.jpg      Anger   \n",
       "1             1     C:/Users/Sbala/Emotion/Images/Test\\Anger\\1.jpg      Anger   \n",
       "2             2    C:/Users/Sbala/Emotion/Images/Test\\Anger\\10.jpg      Anger   \n",
       "3             3    C:/Users/Sbala/Emotion/Images/Test\\Anger\\11.jpg      Anger   \n",
       "4             4    C:/Users/Sbala/Emotion/Images/Test\\Anger\\12.jpg      Anger   \n",
       "..          ...                                                ...        ...   \n",
       "147         147  C:/Users/Sbala/Emotion/Images/Test\\Surprised\\5...  Surprised   \n",
       "148         148  C:/Users/Sbala/Emotion/Images/Test\\Surprised\\6...  Surprised   \n",
       "149         149  C:/Users/Sbala/Emotion/Images/Test\\Surprised\\7...  Surprised   \n",
       "150         150  C:/Users/Sbala/Emotion/Images/Test\\Surprised\\8...  Surprised   \n",
       "151         151  C:/Users/Sbala/Emotion/Images/Test\\Surprised\\9...  Surprised   \n",
       "\n",
       "    predictions  \n",
       "0           Sad  \n",
       "1         Anger  \n",
       "2         Happy  \n",
       "3           Sad  \n",
       "4         Anger  \n",
       "..          ...  \n",
       "147   Surprised  \n",
       "148   Surprised  \n",
       "149   Surprised  \n",
       "150   Surprised  \n",
       "151       Happy  \n",
       "\n",
       "[152 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"test_with_predictions.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bf24c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[152,   0],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[128,   5],\n",
       "        [  4,  15]],\n",
       "\n",
       "       [[130,   3],\n",
       "        [  5,  14]],\n",
       "\n",
       "       [[130,   3],\n",
       "        [  5,  14]],\n",
       "\n",
       "       [[130,   3],\n",
       "        [  4,  15]],\n",
       "\n",
       "       [[132,   1],\n",
       "        [  6,  13]],\n",
       "\n",
       "       [[122,  11],\n",
       "        [  5,  14]],\n",
       "\n",
       "       [[130,   3],\n",
       "        [  5,  14]]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "r = sklearn.metrics.multilabel_confusion_matrix(df[\"label\"], df[\"predictions\"],labels= [ 'Angry', 'Contempt', 'Disgust',  'Fear',  'Happy',  'Neutral',  'Sad', 'Surprised'] )\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cf4aacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = sklearn.metrics.accuracy_score(df[\"label\"], df[\"predictions\"])\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7110c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
